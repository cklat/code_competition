{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianklat/code_competition/venv/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV \n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "def load_csv():\n",
    "    train_df = pd.read_csv(\"../data/verkehrsunfaelle_train.csv\").drop(['Unnamed: 0'],axis=1)\n",
    "    test_df = pd.read_csv(\"../data/verkehrsunfaelle_test.csv\").drop(['Unnamed: 0'],axis=1)\n",
    "    \n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collective Function for renaming Columns and Feature values of the datasetto ensure naming consistency\n",
    "def rename_data(df):\n",
    "    renamed_df = df.copy()\n",
    "    \n",
    "    #Rename Time (=\"Zeit\") column\n",
    "    renamed_df.rename(columns={\"Zeit (24h)\": \"Zeit\"}, inplace=True)\n",
    "    \n",
    "    #Correcting notation of values from the Feature 'Bodenbeschaffenheit'\n",
    "    renamed_df[\"Bodenbeschaffenheit\"].replace(\"Frost/ Ice\", \"Frost / Eis\", inplace=True)\n",
    "    \n",
    "    return renamed_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collectively filter rows that seem to be unimportant according to the EDA notebook\n",
    "def clear_rows(df):\n",
    "    cleared_df = df.copy()\n",
    "    \n",
    "    #drop the instance with the Feature value \"Bodenbeschaffenheit = 9\"\n",
    "    cleared_df.drop(cleared_df.loc[cleared_df[\"Bodenbeschaffenheit\"]==\"9\"].index, inplace=True)\n",
    "    \n",
    "    #drop instances with Feature value \"Fahrzeugtyp = Unbekannt/Pferd/Traktor\"\n",
    "    cleared_df.drop(cleared_df.loc[cleared_df[\"Fahrzeugtyp\"]==\"Unbekannt\"].index, inplace=True)\n",
    "    cleared_df.drop(cleared_df.loc[cleared_df[\"Fahrzeugtyp\"]==\"Pferd\"].index, inplace=True)\n",
    "    cleared_df.drop(cleared_df.loc[cleared_df[\"Fahrzeugtyp\"]==\"Traktor\"].index, inplace=True)\n",
    "\n",
    "    #drop instances with Feature value \"Wetterlage = Schnee (starker Wind)\"\n",
    "    cleared_df.drop(cleared_df.loc[cleared_df[\"Wetterlage\"]==\"Schnee (starker Wind)\"].index, inplace=True)\n",
    "                                                  \n",
    "    return cleared_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process and convert the date representations in the dataset and perform one-hot-encoding\n",
    "def process_date(df, use_day=False):\n",
    "    dateconverted_df = df.copy()\n",
    "    dateconverted_df[\"Unfalldatum\"] = dateconverted_df[\"Unfalldatum\"].apply(lambda x: x[:x.rfind('-')] + '-2016') \\\n",
    "                                                 .apply(lambda x: x.replace(\". \", \"-\")) \\\n",
    "                                                 .apply(lambda x: x.split('.', 1)[0])[:]\n",
    "\n",
    "\n",
    "    conversions = {\"Mrz\": \"Mar\",\n",
    "                   \"Mai\": \"May\",\n",
    "                   \"Okt\": \"Oct\",\n",
    "                   \"Dez\": \"Dec\"}\n",
    "\n",
    "    dateconverted_df[\"Unfalldatum\"] = dateconverted_df[\"Unfalldatum\"].replace(conversions, regex=True)\n",
    "    dateconverted_df[\"Unfalldatum\"] = pd.to_datetime(dateconverted_df[\"Unfalldatum\"], dayfirst=True)\n",
    "    \n",
    "    #one-hot-encode month values of date Feature\n",
    "    dateconverted_df[\"Monat\"] = dateconverted_df[\"Unfalldatum\"].dt.month\n",
    "\n",
    "    dateconverted_df = pd.get_dummies(dateconverted_df, columns=[\"Monat\"])\n",
    "    \n",
    "    if use_day == True:\n",
    "        dateconverted_df[\"Tag\"] = dateconverted_df[\"Unfalldatum\"].dt.day\n",
    "        dateconverted_df = pd.get_dummies(dateconverted_df[\"Unfalldatum\"].dt.day)\n",
    " \n",
    "    dateconverted_df.drop('Unfalldatum', axis=1, inplace=True)\n",
    "    \n",
    "    return dateconverted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the time feature and perform one-hot-encoding to make it usable for the algorithm\n",
    "def process_time(df):\n",
    "    timeconverted_df = df.copy()\n",
    "\n",
    "    def append_zeros(x):\n",
    "        if len(str(x)) == 3:\n",
    "            return \"0\" + str(x)[0] + \":\" + str(x)[-2:]\n",
    "        if len(str(x)) == 2:\n",
    "            return \"00:\" + str(x)\n",
    "        if len(str(x)) == 4:\n",
    "            return str(x)[:2] + \":\" + str(x)[-2:]\n",
    "    \n",
    "    timeconverted_df[\"Zeit\"] = timeconverted_df[\"Zeit\"].apply(append_zeros)\n",
    "    timeconverted_df[\"Zeit\"] = pd.to_datetime(timeconverted_df[\"Zeit\"], format=\"%H:%M\")\n",
    "    \n",
    "    #We drop the minutes of the time representations in order to able to perform a one-hot-encoding. Keeping\n",
    "    #the minutes would make the amount of unique values for this feature very large \n",
    "    #and we would generate a great number of new one-hot-encoded columns. \n",
    "    #It's fair to assume that the exact minute of an accident shouldn't be a reasonable predictor\n",
    "    timeconverted_df[\"Stunde\"] = timeconverted_df[\"Zeit\"].dt.hour\n",
    "    timeconverted_df = pd.get_dummies(timeconverted_df, columns=[\"Stunde\"])\n",
    "    \n",
    "    timeconverted_df.drop(\"Zeit\", axis=1, inplace=True)\n",
    "    \n",
    "    return timeconverted_df\n",
    "\n",
    "                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_HOT_COLS = [\"Strassenklasse\", \"Unfallklasse\", \"Lichtverh√§ltnisse\", \"Bodenbeschaffenheit\", \"Geschlecht\", \n",
    "               \"Fahrzeugtyp\", \"Wetterlage\"]\n",
    "\n",
    "#Collective one-hot-enconding function for categorical columns\n",
    "def one_hot_encoder(df):\n",
    "    orig_cols = list(df.columns)\n",
    "    df = pd.get_dummies(df, columns=ONE_HOT_COLS)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_df):\n",
    "    \n",
    "    features = [f for f in train_df.columns if f not in [\"Unfallschwere\"]]\n",
    "    \n",
    "    model.fit(dtrain[features], dtrain[\"Unfallschwere\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, test_df):\n",
    "    \n",
    "    #Predict test set:\n",
    "    features = [f for f in test_df.columns]\n",
    "\n",
    "    test_predictions = model.predict(test_df[features])\n",
    "    #test_predprob = alg.predict_proba(test_df[features])[:,1]\n",
    "    \n",
    "    test_predictions = pd.DataFrame(test_predictions).reset_index()\n",
    "    \n",
    "    test_predictions.to_csv(path_or_buf=\"../submission.csv\", header=[\"Unfall_ID\", \"Unfallschwere\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(train_df, test_df):\n",
    "    \n",
    "    train_df = clear_rows(train_df)\n",
    "    \n",
    "    df = train_df.append(test_df).reset_index()\n",
    "    df = rename_data(df)\n",
    "    df = one_hot_encoder(df)\n",
    "    df = process_time(df)\n",
    "    df = process_date(df)\n",
    "    \n",
    "    train_df = df[0:-1000]\n",
    "    test_df = df[-1000:df.shape[0]]\n",
    "    train_df = train_df.drop(['index'],axis=1)\n",
    "    test_df = test_df.drop(['Unfallschwere'],axis=1)\n",
    "    test_df = test_df.drop(['index'],axis=1)\n",
    "    \n",
    "    return train_df, test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
